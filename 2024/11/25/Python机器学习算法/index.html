<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"readmengk90.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":{"home":"/","about":"/about","tags":"/tags"}},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="特征工程-k近邻算法-线性回归-逻辑回归-聚类-朴素贝叶斯">
<meta property="og:type" content="article">
<meta property="og:title" content="Python机器学习">
<meta property="og:url" content="https://readmengk90.github.io/2024/11/25/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/index.html">
<meta property="og:site_name" content="东瓶西镜">
<meta property="og:description" content="特征工程-k近邻算法-线性回归-逻辑回归-聚类-朴素贝叶斯">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E8%B7%AF%E7%BA%BF.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E4%B9%A6%E7%B1%8D%E6%8E%A8%E8%8D%90.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/whylearn.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E5%8F%AF%E7%94%A8%E6%95%B0%E6%8D%AE%E9%9B%86.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E7%89%B9%E5%BE%81%E7%9B%AE%E6%A0%87.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/sparse%E7%9F%A9%E9%98%B5.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E5%AD%97%E5%85%B8%E6%95%B0%E6%8D%AE%E6%8A%BD%E5%8F%96.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/onehot-1732519551080-11.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%96%87%E6%9C%AC%E6%8A%BD%E5%8F%96.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/tf_idf.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E5%BD%92%E4%B8%80%E5%8C%96.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E8%A7%84%E5%88%92%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%A0%87%E5%87%86%E5%8C%96.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%B1%82%E6%96%B9%E5%B7%AE.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%A0%87%E5%87%86%E5%8C%96%E5%9B%BE.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/StandardScaler%E8%AF%AD%E6%B3%95-1732623439506-8.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E7%BC%BA%E5%A4%B1%E5%80%BC.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E9%99%8D%E7%BB%B4.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E4%BB%A3%E7%A0%811.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/pca%E8%AF%AD%E6%B3%95.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE%E9%9B%86.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/sklearndata.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E8%BF%94%E5%9B%9E%E7%B1%BB%E5%9E%8B.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E5%89%B2.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E5%9B%9E%E5%BD%92%E6%95%B0%E6%8D%AE%E9%9B%86.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/K%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%AC%A7%E5%BC%8F%E8%B7%9D%E7%A6%BB.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/K%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%9522.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E9%B3%B6%E5%B0%BE%E8%8A%B1%E4%BD%9C%E6%A5%AD.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E8%81%94%E5%90%88%E6%A6%82%E7%8E%87%E5%92%8C%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F%E8%A7%A3%E9%87%8A.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E4%B8%BE%E4%BE%8B%E8%B4%9D%E5%8F%B6%E6%96%AF-1732850040376-7.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%B9%B3%E6%BB%91.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E6%94%B9%E9%80%A0%E5%90%8E-1732850380206-11.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%B7%B7%E6%B7%86%E6%A0%87%E7%AD%BE.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E7%B2%BE%E7%A1%AE%E7%8E%87%E5%8F%AC%E5%9B%9E%E7%8E%87.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/F-score.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/GridSearchCV.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E5%86%B3%E7%AD%96%E6%A0%91%E5%88%92%E5%88%86.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E4%BF%A1%E6%81%AF%E7%86%B5.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E9%93%B6%E8%A1%8C%E8%B4%B7%E6%AC%BE%E6%A1%88%E4%BE%8B.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E5%86%B3%E7%AD%96%E6%A0%91%E5%88%92%E5%88%86.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E5%86%B3%E7%AD%96%E6%A0%91%E7%BB%93%E6%9E%84%E4%BF%9D%E5%AD%98.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/image-20241202203931785.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97API.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E7%9F%A9%E9%98%B5.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E8%AF%AF%E5%B7%AE.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E5%A4%9A%E5%8F%98%E9%87%8F.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/W.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9B%B4%E8%A7%82%E5%9B%BE.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D01.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%A2%AF%E5%BA%A6%E5%9B%BE.gif">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E6%96%B9%E6%B3%95.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%AD%A3%E8%A7%84%E6%A2%AF%E5%BA%A6%E5%AF%B9%E6%AF%94.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%8B%9F%E5%90%88.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E6%8B%9F%E5%90%8801.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E5%B2%AD%E5%9B%9E%E5%BD%92.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/sigmoid%E5%87%BD%E6%95%B0.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%AE%8C%E6%95%B4%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E8%81%9A%E7%B1%BB01.png">
<meta property="og:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E8%81%9A%E7%B1%BB%E6%A0%B7%E6%9C%AC%E5%88%86%E6%9E%90.png">
<meta property="article:published_time" content="2024-11-25T01:55:10.924Z">
<meta property="article:modified_time" content="2024-12-22T11:09:21.490Z">
<meta property="article:author" content="Amber">
<meta property="article:tag" content="Python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://readmengk90.github.io/2024/11/25/images/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E8%B7%AF%E7%BA%BF.png">

<link rel="canonical" href="https://readmengk90.github.io/2024/11/25/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Python机器学习 | 东瓶西镜</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="东瓶西镜" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">东瓶西镜</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Welcome to my blog</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-photos">

    <a href="/photos/" rel="section"><i class="fa fa-camera fa-fw"></i>photos</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/readMengK90/readMengK90.github.io.git" class="github-corner" title="readMengK90 GitHub" aria-label="readMengK90 GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://readmengk90.github.io/2024/11/25/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Amber">
      <meta itemprop="description" content="programming study">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="东瓶西镜">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Python机器学习
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-11-25 09:55:10" itemprop="dateCreated datePublished" datetime="2024-11-25T09:55:10+08:00">2024-11-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-12-22 19:09:21" itemprop="dateModified" datetime="2024-12-22T19:09:21+08:00">2024-12-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>16k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>29 分钟</span>
            </span>
            <div class="post-description"><center>特征工程-k近邻算法-线性回归-逻辑回归-聚类-朴素贝叶斯</center></div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><strong>越努力越幸运</strong></p>
<p><img src="../images/Python机器学习算法/路线.png" alt=""></p>
<h3 id="机器学习简介"><a href="#机器学习简介" class="headerlink" title="机器学习简介"></a>机器学习简介</h3><p>机器学习领域:(图像识别，自然语言处理，传统预测)</p>
<p>机器学习库和框架:  <code>scikit learn</code>,<code>tensorflow(深度)</code>，<code>pytorch(深度)</code></p>
<p>学习书籍推荐:</p>
<p><img src="../images/Python机器学习算法/书籍推荐.png" alt=""></p>
<p>课程目标：</p>
<pre><code>1. 熟悉机器学习各类算法的原理
1. 掌握算法的使用，能够结合场景解决实际问题
1. 掌握使用机器学习算法库和框架的技能
</code></pre><p>机器学习课程概要：(特征工程；模型，策略，优化；分类，回归，聚类；Tensorflow;神经网络；图像识别；自然语言处理)</p>
<h3 id="day01-数据的特征工程"><a href="#day01-数据的特征工程" class="headerlink" title="day01:数据的特征工程"></a>day01:数据的特征工程</h3><h4 id="机器学习概述"><a href="#机器学习概述" class="headerlink" title="机器学习概述"></a>机器学习概述</h4><p>定义:机器学习是从<code>数据</code>中自动分析获得<code>规律</code>(模型),并利用规律对<code>未知数据进行预测</code></p>
<p><img src="../images/Python机器学习算法/whylearn.png" alt=""></p>
<p>机器学习的目的是让机器学习程序替换手动的步骤，减少企业的成本也提高企业的效率。</p>
<h4 id="数据集的构成"><a href="#数据集的构成" class="headerlink" title="数据集的构成"></a>数据集的构成</h4><p>机器学习的数据:文件<code>csv</code></p>
<p><code>mysql</code>数据库是有性能瓶颈的，读取速度；格式不太符合机器学习要求数据的格式</p>
<p>可用的数据集：</p>
<p><img src="../images/Python机器学习算法/可用数据集.png" alt=""></p>
<h4 id="数据集的结构组成"><a href="#数据集的结构组成" class="headerlink" title="数据集的结构组成"></a>数据集的结构组成</h4><p>结构：特征值+目标值（注:有些数据集可以没有目标值)</p>
<p><img src="../images/Python机器学习算法/特征目标.png" alt=""></p>
<h4 id="数据中对特征的处理"><a href="#数据中对特征的处理" class="headerlink" title="数据中对特征的处理"></a>数据中对特征的处理</h4><p>pandas:一个数据读取非常方便以及基本的处理格式工具。</p>
<p>sklearn:对于<code>特征的处理</code>提供了强大的接口。</p>
<p>特征工程:将原始数据转换为更好地代表预测模型的潜在问题的特征的过程，从而提高了对未知数据的预测准确性。</p>
<p><img src="../images/Python机器学习算法/特征工程.png" alt=""></p>
<h4 id="特征工程的意义"><a href="#特征工程的意义" class="headerlink" title="特征工程的意义:"></a>特征工程的意义:</h4><p>直接会影响预测结构</p>
<h4 id="scikit-learn库的介绍："><a href="#scikit-learn库的介绍：" class="headerlink" title="scikit-learn库的介绍："></a>scikit-learn库的介绍：</h4><p>Python语言的机器学习工具</p>
<p>Scikit-learn包括许多知名的机器学习算法的实现</p>
<p>Scikit-learn文档完善，容易上手，丰富的API，使其在学术界颇受欢迎，目前文档版本0.19</p>
<p><code>下载安装Scikit-learn</code></p>
<p>确保你的计算机已经安装了 <strong>Python 3</strong> 和 <strong>pip</strong>。</p>
<p>安装scikit-learn需要Numpy,pandas等库</p>
<p>在 Windows 上安装 Python 3</p>
<ol>
<li><p><strong>下载 Python 安装程序</strong>：</p>
<ul>
<li>访问 Python 官网：<a target="_blank" rel="noopener" href="https://www.python.org/downloads/">https://www.python.org/downloads/</a></li>
<li>点击 “Download Python 3.x.x”（最新版本）。</li>
</ul>
</li>
<li><p><strong>运行安装程序</strong>：</p>
<ul>
<li>双击下载的 <code>.exe</code> 安装程序。</li>
<li>在安装界面，确保勾选 “<strong>Add Python to PATH</strong>” 选项，这是为了让你在命令行中方便地使用 Python。</li>
<li>选择 <strong>Install Now</strong> 来进行默认安装，或者选择 <strong>Customize installation</strong> 来进行自定义安装</li>
</ul>
</li>
<li><p><strong>验证安装</strong>： 安装完成后，打开命令提示符（按 <code>Win + R</code>，输入 <code>cmd</code> 然后回车），输入以下命令来检查 Python 是否安装成功：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python --version</span><br></pre></td></tr></table></figure>
<p>如果安装成功，你应该看到类似于以下的输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Python 3.x.x</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>​    1. <strong>使用 pip 安装</strong></p>
<p>打开命令行终端（在 Windows 上使用命令提示符或 PowerShell，在 macOS/Linux 上使用终端），然后输入以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scikit-learn</span><br></pre></td></tr></table></figure>
<p>这将会安装最新版本的 Scikit-learn 及其所需的依赖。</p>
<p>​    2. <strong>验证安装</strong></p>
<p>安装完成后，打开 Python 解释器（在终端中输入 <code>python</code> 或 <code>python3</code>），然后输入以下代码来验证 Scikit-learn 是否安装成功：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import sklearn</span><br><span class="line">print(sklearn.__version__)</span><br></pre></td></tr></table></figure>
<p>如果安装成功，你应该看到类似于以下的输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.24.1</span><br></pre></td></tr></table></figure>
<h4 id="数据的特征抽取"><a href="#数据的特征抽取" class="headerlink" title="数据的特征抽取:"></a>数据的特征抽取:</h4><p>特征抽取对文本等数据进行特征值化</p>
<p><strong>字典特征抽取</strong>:对字典数据进行特征值化</p>
<p>类：<code>sklearn.feature_extraction.DictVectorizer</code></p>
<p>DictVectorizer语法：DictVectorzer(sparse=True,……)</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><code>DictVectorizer.fit_transform(X)</code></th>
<th>X:字典或者包含字典的迭代器</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>返回值：返回sparse矩阵</td>
</tr>
<tr>
<td><code>DictVectorizer.inverse_transform(X)</code></td>
<td>X:array数组或者sparse矩阵</td>
</tr>
<tr>
<td></td>
<td>返回值：转换之前的数据格式</td>
</tr>
<tr>
<td><code>DictVectorizer.transform(X)</code></td>
<td>返回类别名称</td>
</tr>
<tr>
<td><code>DictVectorizer.get_feature_names(X)</code></td>
<td>按照原先的标准转换</td>
</tr>
</tbody>
</table>
</div>
<p>流程：</p>
<p>导包:<code>from sklearn.feature_extraction import DictVectorizer</code></p>
<ol>
<li>实例化类<code>DictVectorizer</code>,默认返回sparse矩阵的形式</li>
<li>调用<code>fit_transform</code>方法输入数据并转换</li>
</ol>
<p>sparse矩阵:(节约内存，方便读取处理)</p>
<p><img src="../images/Python机器学习算法/sparse矩阵.png" alt=""></p>
<p><img src="../images/Python机器学习算法/字典数据抽取.png" alt=""></p>
<p><code>one-hot编码分析</code></p>
<p>当您的数据包含标称型属性时，这些属性没有内在的顺序或大小关系。例如，颜色（红、绿、蓝），国家名（中国、美国、法国），等。对于这样的属性，直接用数值表示是不合适的，因为这会给模型带来误导性的信息，即数值间的比较关系。通过one-hot编码，可以为每个类别创建一个新的二进制特征，这样模型就不会错误地认为某些类别之间存在等级或数量上的关系。</p>
<p><img src="../images/Python机器学习算法/onehot-1732519551080-11.png" alt=""></p>
<h5 id="文本特征抽取1"><a href="#文本特征抽取1" class="headerlink" title="文本特征抽取1:"></a><strong>文本特征抽取</strong>1:</h5><p>导包:<code>from sklearn.feature_extraction.text import CountVectorizer</code></p>
<p>​    作用:对<code>文本数据</code>进行特征值化</p>
<p>​    类: <code>sklearn.feature_extraction.text.CountVectorizer</code></p>
<div class="table-container">
<table>
<thead>
<tr>
<th><code>CountVectorizer.fit_transform(X)</code></th>
<th>X:文本或者包含文本字符串的可迭代对象</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>返回值：返回sparse矩阵</td>
</tr>
<tr>
<td><code>CountVectorizer.inverse_transform(X)</code></td>
<td>X:array数组或者sparse矩阵</td>
</tr>
<tr>
<td></td>
<td>返回值:转换之前数据格式</td>
</tr>
<tr>
<td><code>CountVectorizer.get_feature_names()</code></td>
<td>返回值：单词列表,重复的只看做一次</td>
</tr>
</tbody>
</table>
</div>
<p><code>fit_transform()</code>首先使用 <code>fit()</code> 对输入数据进行学习，建立词汇表；然后使用 <code>transform()</code> 将文本数据转换为数值特征矩阵</p>
<p><code>流程</code></p>
<ol>
<li>实列化类<code>CountVectorizer</code></li>
<li><p>调用fit_transform方法输入数据并转换(注意返回格式,利用<code>toarray()</code>进行sparse矩阵转换array数组)</p>
<p>[“life is short,i like python”,”life is too long,i dislike python”]</p>
<p>对每篇文章，在词的列表里面进行统计每个词出现的次数，单个字母不统计。</p>
</li>
</ol>
<p><img src="../images/Python机器学习算法/文本抽取.png" alt=""></p>
<p>文本特征抽取的用途: <code>文本分类</code>，<code>情感分析</code></p>
<p>单个英文字母不统计：不代表文本的主体，没有分类的依据。</p>
<p>中英文杂糅：默认不支持特征提取，以空格分开(分词工具)</p>
<p>分词工具：<code>jieba</code>分词</p>
<p><code>下载</code>: pip3 install jieba</p>
<p><code>使用</code>: import jieba</p>
<p>​       jieba.cut(“我是一个好程序员”)</p>
<p><code>注意</code>: 返回值:词语生成器</p>
<h5 id="文本特征抽取方式2"><a href="#文本特征抽取方式2" class="headerlink" title="文本特征抽取方式2:"></a><strong>文本特征抽取方式2:</strong></h5><p><strong>tf_idf重要性程度：</strong></p>
<p>类：<code>sklearn.feature_extraction.text.TfidfVectorizer</code></p>
<p>Tf:<code>term frequency</code> :词的频率-&gt;统计每篇文章在这个词的列表中出现的次数</p>
<p>idf:<code>inversedocument frequency</code>：逆文档频率-&gt;log(总文档数量/该词出现的文档数量)</p>
<p><code>tf*idf</code>,我们称之为重要性程度</p>
<p>语法:</p>
<p><code>TfidfVectorizer(stop_word=None,.....)</code></p>
<p><img src="../images/Python机器学习算法/tf_idf.png" alt=""></p>
<h4 id="数据的特征预处理"><a href="#数据的特征预处理" class="headerlink" title="数据的特征预处理:"></a>数据的特征预处理:</h4><p>特征预处理：通过特定的统计方法(数学方法)将数据转换成算法要求的数据。</p>
<p>针对的数值型数据:标准缩放(归一化，标准化，缺失值)</p>
<p>类别型数据：one-hot编码</p>
<p>时间类型：时间的切分</p>
<p>特征预处理API:<code>sklearn.preprofessing</code></p>
<h5 id="归一化："><a href="#归一化：" class="headerlink" title="归一化："></a>归一化：</h5><p>特点：通过对原始数据进行变换把数据映射到(默认为[0,1])之间</p>
<p><img src="../images/Python机器学习算法/归一化.png" alt=""></p>
<p><img src="../images/Python机器学习算法/规划计算过程.png" alt=""></p>
<p>sklearn归一化API:</p>
<p><code>sklearn.preprocessing.MinMaxScaler</code></p>
<p>MinMaxScaler语法：</p>
<p><code>MinMaxScalar(feature_range=(0,1)......)</code></p>
<p>​    每个特征缩放到给定范围(默认[0，1])</p>
<p>​    <code>MinMaxScalar.fit_transform(X)</code></p>
<p>​        X:numpy array格式的数据[n_samples,n_features]</p>
<p>​        返回值：转换后的形状相同的array</p>
<p>归一化步骤：</p>
<pre><code>1. 实列化`MinMaxScaler`
1. 通过fit_transform转换
</code></pre><p>想要多个特征同等重要，需要进行归一化处理，使得某一个特征对最终结果不会造成更大影响。</p>
<p>归一化总结:</p>
<p>注意在特定场景下最大值最小值是变化的，另外，最大值与最小值非常容易受到异常点的影响，所以，这种方法</p>
<p>的<code>鲁棒性</code>(稳定性)较差，只适合传统精确小数据场景。</p>
<h5 id="标准化："><a href="#标准化：" class="headerlink" title="标准化："></a>标准化：</h5><p>特点：通过对原始数据进行变换把数据变换到<code>均值为0</code>，<code>标准差为1</code>的范围内</p>
<p><img src="../images/Python机器学习算法/标准化.png" alt=""></p>
<p><img src="../images/Python机器学习算法/求方差.png" alt=""></p>
<p>var=[(90-75)^2+(60-75)^2+(75-75)^2]/3=150</p>
<p>σ=√150</p>
<p>异常的对平均值的影响很小</p>
<p><strong>方差考量了数据的稳定性，方差小表示数据比较集中，方差大表示数据比较分散。</strong></p>
<p><img src="../images/Python机器学习算法/标准化图.png" alt=""></p>
<p>结合归一化来谈标准化：</p>
<p>​    对于归一化来说：如果出现异常点，影响了最大值和最小值，那么结果显然会发生改变</p>
<p>​    对于标准化来说：如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响并不大，从而方差改变较小。</p>
<p><code>标准化的API:</code></p>
<p>​    <code>scikit-learn.preprocessing.StandardScaler</code></p>
<p><img src="../images/Python机器学习算法/StandardScaler语法-1732623439506-8.png" alt=""></p>
<p><code>标准化步骤</code></p>
<ol>
<li>实例化<code>StandardScaler</code></li>
<li>通过fit_transform转换</li>
</ol>
<p>标准化总结：在已有样本足够多的情况下比较稳定，适合限制嘈杂大数据场景。</p>
<p>数值型数据标准缩放的方法：1.归一化；2.标准化；3.缺失值</p>
<p>类别型数据:one-hot编码</p>
<p>时间类型：时间的切分</p>
<h5 id="缺失值处理方法"><a href="#缺失值处理方法" class="headerlink" title="缺失值处理方法:"></a>缺失值处理方法:</h5><p>删除：如果每列或者行数据缺失值达到一定的比例，建议放弃整行或者整列</p>
<p>插补：可以通过缺失值每行或者<strong>每列</strong>的平均值，中位值来填充。</p>
<p>缺失值API:<code>sklearn.processing.Imputer</code></p>
<p>数据当中的缺失值:np.nan(float类型）</p>
<p><img src="../images/Python机器学习算法/缺失值.png" alt=""></p>
<h4 id="数据的降维"><a href="#数据的降维" class="headerlink" title="数据的降维:"></a>数据的降维:</h4><p>降维中的维度指的是<code>特征的数量</code></p>
<h5 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h5><p><code>特征选择的原因：</code></p>
<p>​    冗余:部分特征的相关度高，容易消耗计算性能</p>
<p>​    噪声:部分特征对预测结果有影响</p>
<p><code>特征选择是什么:</code></p>
<p>​    就是单纯从提取到的所有特征中选择部分特征作为训练集特征，特征在选择前和选择后可以改变值，也不改变值，但是选择后的特征维数肯定比选择前小，毕竟我们只选择了其中的一部分特征。</p>
<p><code>特征选择的主要方法：</code></p>
<p>​    Filter(过滤式)：Variance Threshold(从方差大小来考虑这个特征所有样本的数据情况)</p>
<p>​    Embedded(嵌入式):正则化，决策树</p>
<p>​    Wrapped(包裹式):</p>
<p><code>特征选择API:</code>    <code>sklearn.feature_selection.VarianceThreshold</code></p>
<p><img src="../images/Python机器学习算法/降维.png" alt=""></p>
<p><code>VarianceThreshold流程：</code></p>
<ol>
<li>初始化<code>VarianceThreshold</code>，指定阈值方差</li>
<li>调用<code>fit_transform</code></li>
</ol>
<p><img src="../images/Python机器学习算法/代码1.png" alt=""></p>
<h5 id="主成分分析-PCA"><a href="#主成分分析-PCA" class="headerlink" title="主成分分析(PCA)"></a>主成分分析(PCA)</h5><p><code>主成分分析的API：</code></p>
<p>​    <code>sklearn.decomposition</code></p>
<p><img src="../images/Python机器学习算法/pca语法.png" alt=""></p>
<p><code>n_components</code>:小数形式0~1</p>
<p>​                整数形式减少到的特征数量</p>
<p><code>PCA流程：</code></p>
<ol>
<li>初始化PCA,指定减少后的维度</li>
<li>调用fit_transform</li>
</ol>
<p><code>场景：</code></p>
<p>​    PCA：当特征数量达到上百的时候就要考虑数据的简化问题(简化数据集的同时将损失降到最小)</p>
<p>​    <img src="../images/Python机器学习算法/简化数据集.png" alt=""></p>
<h3 id="day02-课程第二天"><a href="#day02-课程第二天" class="headerlink" title="day02 课程第二天"></a>day02 课程第二天</h3><h4 id="sklearn数据集与估计器"><a href="#sklearn数据集与估计器" class="headerlink" title="sklearn数据集与估计器"></a>sklearn数据集与估计器</h4><p>数据集分为训练集(特征值，目标值)和测试集(特征值，目标值)</p>
<p>train_test_split()</p>
<p>训练数据:用于训练，构建模型</p>
<p>测试数据:在模型检验时使用，用于评估模型是否有效</p>
<p>scikit-learn数据集API介绍：</p>
<p><img src="../images/Python机器学习算法/sklearndata.png" alt=""></p>
<p>获取数据集返回的类型:</p>
<p><img src="../images/Python机器学习算法/返回类型.png" alt=""></p>
<p>sklearn数据集划分API：</p>
<p><code>sklearn.model_selection.train_test_split</code></p>
<p>数据集进行分割：</p>
<p><img src="../images/Python机器学习算法/数据集分割.png" alt=""></p>
<p>用于分类的大数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sklearn.datasets.fetch_20newsgroups(data_home=<span class="literal">None</span>,subset=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line"><span class="comment"># subset:&quot;train&quot;或者&quot;test all&quot;,可选，选择要加载的数据集，训练集的训练，测试集的测试，两者的全部</span></span><br><span class="line">datasets.clear_data_home(data_home)=<span class="literal">None</span></span><br><span class="line"><span class="comment"># 清楚目录下的数据</span></span><br></pre></td></tr></table></figure>
<p>sklearn回归数据集：</p>
<p><img src="../images/Python机器学习算法/回归数据集.png" alt=""></p>
<p>特征工程的步骤:</p>
<p>​    实例化(实例化的就是一个转换器类)</p>
<p>​    调用fit_transform(对于文档简历分类词频矩阵，不能同时调用)</p>
<p>转换器：</p>
<p>估计器：实现了一类算法得API</p>
<p>​    流程：fit 训练数据</p>
<p>​           predict预测测试集得结果</p>
<p>​           score得出准确率</p>
<h4 id="机器学习基础"><a href="#机器学习基础" class="headerlink" title="机器学习基础"></a>机器学习基础</h4><p>算法是核心，数据和计算是基础。</p>
<p>大部分复杂模型的算法设计都是算法 工程事在做，而我们分析很多的数据，分析具体的业务，应用常见的算法，特征工程，调参数，优化。</p>
<p><code>数据类型</code>:</p>
<p>离散型数据:由记录不同类别个体的数目得到的数据，又称计数数据，所有这些数据全部都是整数，而且不能再细分，也不能进一步提高他们的精确度。</p>
<p>连续型数据:变量可以在某个范围内取任一数，即变量的取值可以是连续的，如长度，时间，质量值等，这类类非整数，含有小数部分。</p>
<p>注:只要记住一点，离散型是区间内不可分，连续型是区间内可分。</p>
<p>数据的类型将是机器学习模型不太问题不同处理的依据。</p>
<p><code>机器学习算法分类</code>:</p>
<p>监督学习(预测)：(<strong>特征值+目标值</strong>)</p>
<ul>
<li>分类(<strong>目标值离散型</strong>) k-近邻算法 贝叶斯分类 决策树与随机森林 逻辑回归 神经网络</li>
<li>回归(<strong>目标值连续型</strong>) 线性回归 岭回归</li>
<li>标注 隐马尔可夫模型</li>
</ul>
<p>无监督学习:(特征值)</p>
<ul>
<li>聚类 k-means</li>
</ul>
<p>监督学习:可以由输入数据中学到或建立一个模型，并依次模式推测新的结果。输入数据是由输入特征值和目标值所组成。函数的输出可以是一个连续的值(回归)，或是输出是有限个离散值(称作分类)</p>
<p>无监督学习:可以由输入数据中学到或建立一个模型，并依次模式推测新的结果。输入数据是由输入特征值所组成。</p>
<p><code>机器学习的开发流程</code>:</p>
<p>​          1.公司本身就有数据</p>
<p>1.数据：2.合作过来的数据</p>
<p>​           3.购买的数据</p>
<p>2.原始数据：明确问题做什么(相当于建立模型的过程(分类or回归or非监督学习))</p>
<p>3.数据基本处理：pd去处理(缺失值，合并表)</p>
<p>4.特征工程(特征进行处理)</p>
<p>5.找合适的算法去进行预测分析</p>
<p>6.模型的评估，判断效果</p>
<p>7.上线使用(以<code>API</code>形式提供)</p>
<p>模型：算法+数据</p>
<h4 id="分类算法-k近邻算法-归一化处理"><a href="#分类算法-k近邻算法-归一化处理" class="headerlink" title="分类算法-k近邻算法(归一化处理)"></a>分类算法-k近邻算法(归一化处理)</h4><p><img src="../images/Python机器学习算法/K近邻算法.png" alt=""></p>
<p>定义:如果一个样本在特征空间中的k个最近相似(即特征空间中最邻近)的样本中的大多数属于某一种类别,则该样本也属于这个类别。</p>
<p><code>KNN算法</code>最早是由Cover和Hart提出的一种分类算法。</p>
<p><code>欧氏距离:</code>两个样本的距离可以通过如下公式计算</p>
<p><img src="../images/Python机器学习算法/欧式距离.png" alt=""></p>
<p>K-近邻算法需要做标准化处理。</p>
<p><code>sklerarn k-近邻算法的API</code>:</p>
<ul>
<li><p><code>sklearn.neighbors.KNeighborsClassifier(n_neighbors=5,algorithm=&#39;auto&#39;)</code></p>
<ul>
<li><p>n_neighbors:  int,可选(默认=5)，k_neighbors查询默认使用的邻居数</p>
</li>
<li><p>algorithm:{‘auto’,’ball_tree’,’kd_tree’,’brute’},可选用于计算最近邻居的算法，‘ball_tree’将使用BallTree.</p>
<p>‘kd_tree’将使用KDTree.’auto’将尝试根据传递给fit方法的值来决定最合适的算法。</p>
</li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.kaggle.com/c/facebook-v-predicting-check-ins/data">https://www.kaggle.com/c/facebook-v-predicting-check-ins/data</a></p>
<p><img src="../images/Python机器学习算法/K近邻算法22.png" alt=""></p>
<p><img src="../images/Python机器学习算法/鳶尾花作業.png" alt=""></p>
<p>分类模型的评估：目标值是离散型</p>
<p>准确率</p>
<p>精确率和召回率：混淆矩阵</p>
<h4 id="分类算法-朴素贝叶斯算法"><a href="#分类算法-朴素贝叶斯算法" class="headerlink" title="分类算法-朴素贝叶斯算法"></a>分类算法-朴素贝叶斯算法</h4><p>概率基础：概率定义为一件事情发生的可能性。</p>
<p>联合概率和条件概率:</p>
<p><img src="../images/Python机器学习算法/联合概率和条件概率.png" alt=""></p>
<p>A1,A2相互独立是指A1和A2不是相互影响的，<code>条件独立的</code>,自然语言处理处理不独立的情况。</p>
<p>使用朴素贝叶斯算法的前提是特征条件是独立的。</p>
<p><img src="../images/Python机器学习算法/贝叶斯公式.png" alt=""></p>
<p><img src="../images/Python机器学习算法/朴素贝叶斯公式解释.png" alt=""></p>
<h4 id="朴素贝叶斯算法实列"><a href="#朴素贝叶斯算法实列" class="headerlink" title="朴素贝叶斯算法实列"></a>朴素贝叶斯算法实列</h4><p><img src="../images/Python机器学习算法/举例贝叶斯-1732850040376-7.png" alt=""></p>
<p><code>0/121合理吗？</code></p>
<p><img src="../images/Python机器学习算法/拉普拉斯平滑.png" alt=""></p>
<p><img src="../images/Python机器学习算法/拉普拉斯改造后-1732850380206-11.png" alt=""></p>
<p><code>朴素贝叶斯实现API</code></p>
<p>​    <code>sklearn.naive_bayes.MultinomialNB</code></p>
<p><code>MultinomiaNB</code></p>
<p>​    <code>sklearn.naive_bayes.MultinomialNB(alpha=1.0)</code></p>
<p>​    朴素贝叶斯分类</p>
<p>​    alpha:拉普拉斯平滑系数</p>
<p>分类评估：</p>
<p>混淆矩阵:在分类任务下，预测结果与正确标记之间存在四种不同的组合，构成混淆矩阵(适用于多分类)</p>
<p><img src="../images/Python机器学习算法/混淆标签.png" alt=""></p>
<p><img src="../images/Python机器学习算法/精确率召回率.png" alt=""></p>
<p><code>F1-score</code>反应了模型的稳健性</p>
<p>True Positive（TP）、True Negative（TN）、False Positive（FP）、False Negative（FN）</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>预测值=1</th>
<th>预测值=0</th>
</tr>
</thead>
<tbody>
<tr>
<td>真实值=1</td>
<td>3（TP）</td>
<td>1（FP）</td>
</tr>
<tr>
<td>真实值=0</td>
<td>1（TN）</td>
<td>7（FN）</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>TP = 3（实际患病并被正确预测出来的数量）</li>
<li>FP = 1（实际健康但被错误预测为患病的数量）</li>
<li>TN = 1（实际患病但被错误预测为健康的数量）</li>
<li>FN = 7（实际健康并被正确预测出来的数量）</li>
</ul>
<p><img src="../images/Python机器学习算法/F-score.png" alt=""></p>
<p><code>F1得分</code>得分是精确率（Precision）和召回率（Recall）的调和平均数，常用于评估二分类模型的性能。在数学上，<code>F1</code>得分的计算公式如下：</p>
<p>首先，定义精确率和召回率:</p>
<p>精确率 <code>(Precision) = TP / (TP + FP)</code></p>
<p>召回率 <code>(Recall) = TP / (TP + FN)</code></p>
<p>F1得分 <code>(F1 Score) = 2 * (精确率 * 召回率) / (精确率 + 召回率)</code></p>
<p>分类模型评估API:</p>
<p><code>sklearn.metrics.classification_report</code></p>
<p><code>sklearn.metrics.classification_report(y_true,y_pred,target_names=None)</code></p>
<ul>
<li>y_true:真实目标值</li>
<li>y_pred:估计器预测目标值</li>
<li>target_names:目标类别名称</li>
<li>return：每个类别精确率和召回率</li>
</ul>
<h4 id="模型的选择与调优"><a href="#模型的选择与调优" class="headerlink" title="模型的选择与调优"></a>模型的选择与调优</h4><h3 id="day03-课程第三天"><a href="#day03-课程第三天" class="headerlink" title="day03 课程第三天"></a>day03 课程第三天</h3><h4 id="交叉验证-cross-validation"><a href="#交叉验证-cross-validation" class="headerlink" title="交叉验证(cross validation)"></a>交叉验证(cross validation)</h4><p>为了让被评估的模型更加准确可信，在训练集中选一部分样本用于测试模型。保留一部分的训练集数据作为验证集/评估集，对训练集生成的参数进行测试，相对客观的判断这些参数对训练集之外的数据的符合程度。</p>
<h4 id="K折交叉验证（k-fold-cross-validation）"><a href="#K折交叉验证（k-fold-cross-validation）" class="headerlink" title="K折交叉验证（k-fold cross validation）"></a>K折交叉验证（k-fold cross validation）</h4><p><img src="../images/Python机器学习算法/交叉验证.png" alt=""></p>
<p>​                         把四个准确率求平均值得到一个模型结果</p>
<h4 id="网格搜索-Grid-Search-："><a href="#网格搜索-Grid-Search-：" class="headerlink" title="网格搜索(Grid Search)："></a>网格搜索(Grid Search)：</h4><p><code>Grid Search</code>：一种调参手段/调优方法，在参数列表中进行<strong>穷举搜索</strong>，对每种情况进行训练，找到最优的参数。</p>
<p>穷举搜索：在所有候选的参数选择中，通过循环遍历，尝试每一种可能性，表现最好的参数就是最终的结果。其原理就像是在数组里找最大值。（为什么叫网格搜索？以有两个参数的模型为例，参数a有3种可能，参数b有4种可能，把所有可能性列出来，可以表示成一个3*4的表格，其中每个cell就是一个网格，循环过程就像是在每个网格里遍历、搜索，所以叫grid search）</p>
<p>超参数搜索-网格搜索<code>API</code></p>
<p><code>sklearn.model_selection.GridSearchCV</code></p>
<p><img src="../images/Python机器学习算法/GridSearchCV.png" alt=""></p>
<h4 id="分类算法-决策树"><a href="#分类算法-决策树" class="headerlink" title="分类算法-决策树"></a>分类算法-决策树</h4><p>认识决策树</p>
<p><img src="../images/Python机器学习算法/决策树划分.png" alt=""></p>
<p><code>划分的依据-信息熵</code>：</p>
<p><img src="../images/Python机器学习算法/信息熵.png" alt=""></p>
<p>信息熵公式：信息熵越大不确定性也会随之增大</p>
<ul>
<li><em>p</em>(<em>x</em>) 是 X=<em>x</em> 的概率，即 X取特定值 x 的概率。</li>
</ul>
<script type="math/tex; mode=display">{信息熵}
H(X)=− \sum_{i=1}^n p(x_i)log p(x_i)</script><script type="math/tex; mode=display">
H(X)=− \sum_{k=1}^K\frac{|C_k|}{|D|}log \frac{|C_k|}{|D|}</script><p>决策树的划分依据——<code>信息增益</code>：当得知一个特征条件之后，减少的信息熵的大小</p>
<p>特征A对训练数据集D的信息增益g(D,A)，H(D)为初始信息熵的大小</p>
<script type="math/tex; mode=display">
g(D,A)=H(D)-H(D|A)</script><ul>
<li>注：信息增益表示得知特征X的信息而使得类Y得信息不确定性减少的程度</li>
</ul>
<p>条件熵<code>H(D|A)</code>的计算：衡量的是在已知某些变量的情况下，另一些变量的不确定性</p>
<script type="math/tex; mode=display">
H(D|A)=\sum_{i=1}^n \frac{|D_i|}{|D|}H(D_i)=-\sum_{i=1}^n\frac{|D_i|}{|D|}\sum_{k=1}^K\frac{|D_{ik}|}{|D|}log\frac{|D_{ik}|}{|D|}</script><p>银行贷款分析</p>
<p><img src="../images/Python机器学习算法/银行贷款案例.png" alt=""></p>
<script type="math/tex; mode=display">
H(D)=-(\frac{9}{15}log\frac{9}{15}+\frac{6}{15}log\frac{6}{15})≈0.971 bits</script><script type="math/tex; mode=display">
g(D|年龄)=H(D)-H(D^`|年龄)=0.971-[1/3H(青年)+1/3H(中年)+1/3H(老年)]</script><script type="math/tex; mode=display">
H(青年)=-(\frac{2}{5}log\frac{2}{5}+\frac{3}{5}log\frac{3}{5})=0.97</script><script type="math/tex; mode=display">
H(中年)=-(\frac{2}{5}log\frac{2}{5}+\frac{3}{5}log\frac{3}{5})=0.97</script><script type="math/tex; mode=display">
H(老年)=-(\frac{4}{5}log\frac{4}{5}+\frac{1}{5}log\frac{1}{5})=0.72</script><script type="math/tex; mode=display">
g(D|年龄)=0.971-0.88≈0.091</script><script type="math/tex; mode=display">
g(D|工作)=0.324</script><script type="math/tex; mode=display">
g(D|房子)=0.420</script><script type="math/tex; mode=display">
g(D|信贷情况)=0.363</script><p><img src="../images/Python机器学习算法/决策树划分.png" alt=""></p>
<p><code>ID3-信息增益最大原则</code></p>
<p><code>C4.5-信息增益比最大原则</code></p>
<p><code>CART</code></p>
<ul>
<li>回归树:平方误差最小</li>
<li>分类树:基尼系数最小的原则在<code>sklearn</code>中可以选择划分的默认原则</li>
</ul>
<p>sklearn决策树API:</p>
<p><code>class sklearn.tree.DecisionTreeClassifier(criterion=&#39;gini&#39;,max_deepth=None,random_state=None)</code></p>
<ul>
<li>决策树分类器</li>
<li>criterion：默认是“gini”系数，也可以选择信息增益的熵”entropy“</li>
<li>max_depth:树的深度大小</li>
<li>random_state:随机数种子</li>
<li>method：</li>
<li>decision_path:返回决策树的路径</li>
</ul>
<p><img src="../images/Python机器学习算法/决策树结构保存.png" alt=""></p>
<p>泰坦尼克号乘客生存分类</p>
<p><a target="_blank" rel="noopener" href="http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt">http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt</a></p>
<p>决策树的优缺点:</p>
<p>优点:</p>
<p>简单的理解和解释，树木可视化</p>
<p>需要很少的数据准备，其他技术通常需要数据归一化</p>
<p>缺点:</p>
<p>决策树学习中可以创建不能很好地推广数据的归于复杂的树—过拟合</p>
<p>改进:</p>
<p>减枝cart算法(决策树API当中已经实现，随机森林参数调优有相关介绍)</p>
<p>随机森林</p>
<h4 id="分类算法-随机森林（集成学习方法）"><a href="#分类算法-随机森林（集成学习方法）" class="headerlink" title="分类算法-随机森林（集成学习方法）"></a>分类算法-随机森林（集成学习方法）</h4><p>集成学习通过建立几个模型组合的来解决单一预测问题。它的工作原理是<strong>生成多个分类器/模型</strong>，各自独立地学习和做出预测。这些预测最后结合成单预测，因此优于任何一个单分类的做出预测。</p>
<p>随机森林的定义:在机器学习中，随机森林是一个包括多个决策树的分类器，并且其输出的类别是由个别树输出的众数而定的</p>
<p><strong>众数</strong>是统计学中的一个概念，指的是在一组数据中，出现次数最多的数值。换句话说，众数是数据集中出现频率最高的值。</p>
<p>随机森林建立多个决策树的过程：</p>
<p><code>单个树建立过程(N个样本M个特征):</code></p>
<ol>
<li>随机在N各样本当中选择一个样本，重复N次，样本可能重复</li>
<li>随机在M个特征当中选出m个特征(m&lt;M)    </li>
</ol>
<p>​    建立10颗决策树，样本，特征大多不一样，采用bootstrap抽样</p>
<p><img src="../images/Python机器学习算法/image-20241202203931785.png" alt=""></p>
<p>随机森林<code>API</code>:</p>
<p><img src="../images/Python机器学习算法/随机森林API.png" alt=""></p>
<p>优点：准确率高，不会过拟合，适用于大数据集</p>
<p>分类算法的评估：</p>
<p>​    准确率</p>
<p>​    精确率和召回率</p>
<h4 id="回归算法-线性回归分析"><a href="#回归算法-线性回归分析" class="headerlink" title="回归算法-线性回归分析"></a>回归算法-线性回归分析</h4><p><code>1.分类/回归的问题判断</code></p>
<p>分类:(离散型)分类的目标是将输入数据分配到预先定义好的类别中。其中模型根据已有的训练数据学习如何将新的未见过的数据点映射到这些类别之一。</p>
<p>回归：回归的目标是预测一个连续值的输出，即给定一组特征，预测与之相关的数值结果。但与分类不同的是，回归预测的是数值而不是类别。</p>
<p>如果你的问题是关于“属于哪一类”，那么你可能需要做分类；如果问题是关于“是多少”或者“有多少”，那么你可能需要做回归。例如，预测客户是否会购买产品是一个分类问题（买/不买），而预测客户会购买多少金额的产品则是一个回归问题。</p>
<p><code>2.线性关系模型</code></p>
<p>一个通过<strong>属性的线性组合</strong>来进行预测的函数:</p>
<script type="math/tex; mode=display">
f(x)=w_1x_1+w_2x_2+.......+w_dx_d+b</script><p>w为<strong>权重</strong>，b称为<strong>偏置项</strong>。</p>
<p><img src="../images/Python机器学习算法/线性回归.png" alt=""></p>
<p><code>3.线性回归</code></p>
<p>定义：线性回归通过一个或者多个<strong>自变量</strong>(特征/影响因素)与<strong>因变量</strong>（目标值）之间进行建模的回归分析。<strong>其中可以为一个或多个自变量之间的线性组合(线性回归的一种)</strong></p>
<p>一元线性回归：涉及到的自变量只有一个</p>
<p>多元线性回归：涉及到的自变量两个或两个以上</p>
<p>线性回归就是找到属性和权重的组合来预测结果。</p>
<p>矩阵:是大多数算法的计算基础,为了满足特定的运算需求应运而生</p>
<p>通用公式:</p>
<script type="math/tex; mode=display">
h(w)=w_0+w_1x_1+w_2x_2+...=w^Tx</script><p>其中w,x为矩阵：</p>
<script type="math/tex; mode=display">
w=\begin{pmatrix} w_0  \\ w_1 \\w_2 \end{pmatrix},
x=\begin{pmatrix} 1  \\ x_1 \\x_2 \end{pmatrix}</script><p><img src="../images/Python机器学习算法/矩阵.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy  <span class="keyword">as</span> np</span><br><span class="line">a=[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">7</span>,<span class="number">9</span>]]	<span class="comment">#3行4列</span></span><br><span class="line">b=[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>]	<span class="comment">#1行4列</span></span><br><span class="line">np.multiply(a,b) <span class="comment">#将两个数组 a 和 b 中相应位置的元素相乘</span></span><br><span class="line">Out[<span class="number">6</span>]:</span><br><span class="line">    array([[<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>],</span><br><span class="line">           [<span class="number">10</span>,<span class="number">12</span>,<span class="number">14</span>,<span class="number">16</span>],</span><br><span class="line">           [<span class="number">4</span>,<span class="number">6</span>,<span class="number">14</span>,<span class="number">18</span>]])</span><br><span class="line">b=[[<span class="number">2</span>],[<span class="number">2</span>],[<span class="number">2</span>],[<span class="number">2</span>]]	<span class="comment">#4行1列  </span></span><br><span class="line">np.dot(a,b)</span><br><span class="line">Out[<span class="number">8</span>]:</span><br><span class="line">    array([[<span class="number">20</span>],</span><br><span class="line">           [<span class="number">52</span>],</span><br><span class="line">           [<span class="number">42</span>]])  </span><br></pre></td></tr></table></figure>
<p><code>4.损失函数(误差大小)</code>：预测结果与真实结果存在偏差</p>
<p>​    迭代算法(回归属于迭代算法)是指通过重复一系列步骤或操作来逐步解决问题的方法(逐步优化)。在每次迭代中，算法会基于前一次的结果更新其状态或参数，直到满足某个终止条件为止。迭代算法广泛应用于计算机科学、数学和机器学习等领域。</p>
<p><img src="../images/Python机器学习算法/误差.png" alt=""></p>
<p>​    <img src="../images/Python机器学习算法/多变量.png" alt=""></p>
<p>回归:知道有误差，也会去不断减少误差</p>
<p>损失函数：</p>
<p>​    </p>
<script type="math/tex; mode=display">
y_i为第i个训练样本的真实值</script><script type="math/tex; mode=display">
h_w(x_i)为第i个训练样本呢 特征值组合预测函数</script><p>总损失函数定义：</p>
<script type="math/tex; mode=display">
J(θ)=(h_w(x_1)-y_1)^2+(h_w(x_2)-y_2)^2+...+(h_w(x_m)-y_m)^2=\sum_{i=1}^m(h_w(x_i)-y_i)^2</script><p>又称为<strong>最小二乘法</strong>(误差平方和)</p>
<p><code>5.误差优化-寻找最优化的w</code>：目的是找到最小损失对应的W值</p>
<p>方法1——<code>正规方程</code>（普通最小二乘法）</p>
<script type="math/tex; mode=display">
直接求解正规方程 w=(X^TX)^{-1}X^Ty来获得最优参数</script><p>X为特征值矩阵，y为目标值矩阵</p>
<script type="math/tex; mode=display">
X=\begin{bmatrix} [1 & 2 & 3 & 4]\\ [3 & 4 & 5 & 6] \\ [20 & 19 & 3 & 4] \\ [6 & 5 & 8 & 9] \end{bmatrix}
\
y=\begin{bmatrix} [200] \\ [150] \\ [300] \\ [260] \end{bmatrix}
\\</script><p><img src="../images/Python机器学习算法/W.png" alt=""></p>
<p><img src="../images/Python机器学习算法/损失函数直观图.png" alt=""></p>
<p>其缺点是当特征过于复杂，求解速度太慢。</p>
<p>方法2——<code>梯度下降</code>：通过迭代更新参数来逐步减少损失函数（如均方误差），直到收敛到局部最小值。</p>
<p><strong>我们以单变量中的w0,w1为例子</strong></p>
<script type="math/tex; mode=display">
w_1=-w_1-a\frac{∂cost(w_0+w_1x_1)}{∂w_1}</script><script type="math/tex; mode=display">
w_0=-w_0-a\frac{∂cost(w_0+w_1x_1)}{∂w_1}</script><script type="math/tex; mode=display">
α为学习速率，需要手动指定,  \ \frac{∂cost(w_0+w_1x_1)}{∂w_1} 表示方向</script><p>理解：沿着这个函数下降(损失减少)的方向找，最后就能找到山谷的最低点，然后更新w值</p>
<p><img src="../images/Python机器学习算法/梯度下降01.png" alt=""></p>
<p>使用：面对训练数据规模十分庞大的任务</p>
<p><img src="../images/Python机器学习算法/梯度下降.png" alt=""></p>
<p><img src="../images/Python机器学习算法/梯度图.gif" alt=""></p>
<p>初始的直线是如何建立的？随机给的w值然后逐步优化</p>
<p><img src="../images/Python机器学习算法/统计学方法.png" alt=""></p>
<h4 id="线性回归实例-需要做标准化处理【K近邻-线性回归】"><a href="#线性回归实例-需要做标准化处理【K近邻-线性回归】" class="headerlink" title="线性回归实例(需要做标准化处理【K近邻+线性回归】)"></a>线性回归实例(需要做标准化处理【K近邻+线性回归】)</h4><p>正规方程<code>API</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.linear_model.LinearRegression</span><br></pre></td></tr></table></figure>
<ul>
<li>普通最小二乘线性回归</li>
<li><code>coef_</code>:回归系数</li>
</ul>
<p>梯度下降<code>API</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.linear_model.SGDRegressor</span><br></pre></td></tr></table></figure>
<ul>
<li>通过使用<code>SGD</code>最小化线性模型</li>
<li><code>coef_</code>:回归系数</li>
</ul>
<p>手动指定学习率：内部会自动指定</p>
<p><code>scikit-learn</code>优点：封装好，建立模型简单，预测简单</p>
<p>​                   缺点：算法的过程，有些参数都在算法<code>API</code>内部优化</p>
<p>例子：波士顿房价数据</p>
<p><code>y_predict=lr.predict(x_test)</code></p>
<h4 id="回顾性能评估"><a href="#回顾性能评估" class="headerlink" title="回顾性能评估"></a>回顾性能评估</h4><p>均方误差评估机制:</p>
<script type="math/tex; mode=display">
MSK=\frac{1}{m}\sum_{m=1}^m(y^i-\overline y)^2
\\
注:y^i为预测值，\overline y为真实值</script><p>sklearn回归评估API</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.mean_squared_error</span><br></pre></td></tr></table></figure>
<ul>
<li>mean_squared_error(y_true , y_pred)<ul>
<li>均方误差回归损失</li>
<li>y_true:真实值</li>
<li>y_pred:预测值</li>
<li>return：浮点数结果</li>
</ul>
</li>
<li>注：真实值，预测值为<strong>标准化之前的值</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(mean_squared_error(y_true.inverse_transform(y_test) , y_pred))</span><br></pre></td></tr></table></figure>
<p><img src="../images/Python机器学习算法/正规梯度对比.png" alt=""></p>
<p><code>6.过拟合和欠拟合</code></p>
<p>欠拟合:当一个<strong>模型过于简单</strong>，以至于无法捕捉到训练数据中的基本模式或趋势时，就会发生欠拟合。这意味着模型既不能很好地拟合训练数据，也无法在新数据上做出准确的预测。【学的少】</p>
<ul>
<li>解决办法：增加数据的特征数量</li>
</ul>
<p>过拟合：当一个<strong>模型过于复杂</strong>，以至于它不仅学到了训练数据中的有用信息，还记住了噪声和其他随机波动，这就会导致过拟合。结果是，虽然模型在训练数据上的表现非常好，但在未见过的数据上的泛化性能却很差。【学的多但学错了】</p>
<ul>
<li>解决办法：<ul>
<li>进行特征选择，消除关联性大的特征(很难做)</li>
<li>交叉验证(让所有数据都有过训练(测试集训练集))</li>
<li>正则化(了解)：减少某些特征的权重调整到趋近于0</li>
</ul>
</li>
</ul>
<p><img src="../images/Python机器学习算法/拟合.png" alt=""></p>
<p><img src="../images/Python机器学习算法/拟合01.png" alt=""></p>
<p><strong>正规方程不能很好解决过拟合问题</strong></p>
<p>线性回归：数据的特征值和目标值之间的关系不仅仅是线性关系是模型复杂的原因</p>
<p>L2正则化：</p>
<p>作用：可以使得W的每个元素都很小，都接近于0</p>
<p>优点：越小的参数说明模型越简单(减少高次项)，越简单的模型则越不容易产生过拟合现象</p>
<p><strong>回归：解决过拟合的方式</strong></p>
<p>线性回归：<code>LinearRegression</code>容易出现过拟合，为了把训练集数据表现更好</p>
<p>L2正则化：Ridge岭回归 带有正则化的线性回归 解决过拟合</p>
<p><code>带有正则化的线性回归-岭回归</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">slearn.linear_model.Ridge</span><br></pre></td></tr></table></figure>
<ul>
<li><code>slearn.linear_model.Ridge(alpha=1.0)</code><ul>
<li>具有<code>L2</code>正则化的线性最小二乘法</li>
<li>alpha：正则化力度 λ（0~1，1~10，通过网格搜索找到最优得力度）</li>
<li>coef_:回归系数</li>
</ul>
</li>
</ul>
<p><img src="../images/Python机器学习算法/岭回归.png" alt=""></p>
<p>​                                                力度越来越大，权重趋近于0</p>
<p>岭回归:回归得到得回归系数更符合实际，更可靠。另外，能让估计参数得波动范围变小，变得更稳定。在存在病态数据偏多得研究中有较大得实际价值。</p>
<p><strong>sklearn模型的保存与加载：</strong></p>
<p>可以在不同的时间点或不同的环境中重复利用训练好的模型.</p>
<p><code>joblib</code> 是一个专门为 <code>NumPy</code> 数组设计的持久化库，它比标准的 <code>pickle</code> 更高效，尤其是在处理大型数据集时</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.externals import joblib</span><br></pre></td></tr></table></figure>
<p>保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">joblib.dump(rf,<span class="string">&#x27;test.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>加载：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">estimator=joblib.load(<span class="string">&#x27;test.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="分类算法-逻辑回归"><a href="#分类算法-逻辑回归" class="headerlink" title="分类算法-逻辑回归"></a>分类算法-逻辑回归</h4><ol>
<li><code>定义介绍</code></li>
</ol>
<p>逻辑回归：线性回归的式子作为输入，逻辑回归是解决二分类问题的利器。</p>
<script type="math/tex; mode=display">
输入:Z(w)=w_0+w_1x_1+w_2x_2+.....=w^Tx 
\\
(单个样本)</script><p>应用：广告点击率，是否为垃圾邮件，是否患病，金融诈骗，虚假账号</p>
<ol>
<li><p><code>sigmoid函数</code></p>
<script type="math/tex; mode=display">
数学表达式:g(z)=\frac{1}{1+e^{-z}}
\\
这个函数会将输入的实数值(x轴)映射到(0, 1)区间(y轴)内，其图像呈现出一个S形曲线
\\
Sigmoid函数的输出范围是(0, 1)，这使得它非常适合用来表示概率</script><p><img src="../images/Python机器学习算法/sigmoid函数.png" alt=""></p>
</li>
<li><p><code>逻辑回归-损失函数的定义与优化过程</code></p>
<p>与线性回归的原理相同，但由于是分类问题，损失函数不一样，只能通过梯度下降求解</p>
<script type="math/tex; mode=display">
对数似然损失函数：
\\
cost(h_\Theta(x),y)=\begin{cases} -log(h_\Theta(x)), & \text {if $y$ = 1} \\ -log(1-h_\Theta(x)), & \text{if $y$ = 0}\end{cases}</script><p><img src="../images/Python机器学习算法/逻辑回归完整损失函数.png" alt=""></p>
<p>cost损失的值越小，那么预测的类别准确度越高</p>
<p>| 算法     | 策略(损失函数)        | 优化              |<br>| ———— | ——————————- | ————————- |<br>| 逻辑回归 | 对数似然损失          | 梯度下降          |<br>| 线性回归 | 误差平方和/最小二乘法 | 正规方程&amp;梯度下降 |</p>
<p>损失函数：</p>
<p>均方误差：不存在多个局部最低点，只有一个最小值</p>
<p>对数似然损失：多个局部最小值，尽管没有全局最低点，但是效果都是不错的</p>
<p>​    1.多次随机初始化，多次比较最小值结果</p>
<p>​    2.求解过程中，调整学习率</p>
</li>
<li><p><code>逻辑回归API</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.linear_model.LogisticRegression</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ul>
<li>sklearn.linear_model.LogisticRegression(penalty=’l2’,C=1.0)<ul>
<li>Logistic回归分类器</li>
<li>coef_:回归系数</li>
</ul>
</li>
</ul>
<p>良/恶性乳腺癌肿瘤数据</p>
<figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data</span><br></pre></td></tr></table></figure>
<p>数据描述：</p>
<p>(1)699条样本，共11列数据，第一列用语检索的id,后9列分别是与肿瘤相关的医学特征，最后一列表示肿瘤类型的数值。</p>
<p>(2)包含16个缺失值，用“?”标出。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">逻辑回归</th>
<th style="text-align:center">朴素贝叶斯</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">解决问题</td>
<td style="text-align:center">二分类</td>
<td style="text-align:center">多分类问题</td>
</tr>
<tr>
<td style="text-align:center">应用场景</td>
<td style="text-align:center">癌症，二分类需要概率</td>
<td style="text-align:center">文本分类</td>
</tr>
<tr>
<td style="text-align:center">参数</td>
<td style="text-align:center">正则化力度</td>
<td style="text-align:center">没有</td>
</tr>
<tr>
<td style="text-align:center">结果</td>
<td style="text-align:center">判别模型</td>
<td style="text-align:center">生成模型(先验)</td>
</tr>
</tbody>
</table>
</div>
<h4 id="聚类算法-kmeans原理"><a href="#聚类算法-kmeans原理" class="headerlink" title="聚类算法-kmeans原理"></a>聚类算法-kmeans原理</h4><p><code>1.背景介绍</code></p>
<p>监督学习依赖于带有正确答案的数据集来训练模型，</p>
<p>非监督学习旨在从未标记的数据中发现隐藏的结构或模式。</p>
<p><strong>聚类</strong>：一种常见的非监督学习任务是聚类，即根据某些相似性度量将数据点分组到不同的簇中。只知道特征，根据一些指标进行聚类。</p>
<p><img src="../images/Python机器学习算法/聚类01.png" alt=""></p>
<p><code>2.聚类的过程</code></p>
<p>K：把数据划分成多少个类别(k=3)</p>
<p>1.随机在数据当中抽取三个样本，当作三个类别的中心点</p>
<p>2.计算其余的点分别到这三个中心点的距离，每一个样本有三个距离(a,b,c),从中选出距离最近的一个点作为自己的标记。形成三个族群</p>
<p>3.分别计算这三个族群的平均值，把三个平均值与之前的三个旧中心点进行比较</p>
<ul>
<li>如果相同：结束聚类</li>
<li>如果不相同：把这三个平均值当新的中心点，重复第二步    </li>
</ul>
<p><code>3.k-means API</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.cluster.KMeans</span><br></pre></td></tr></table></figure>
<ul>
<li>sklearn.cluster.KMeans(n_clusters=8,init=’k-means++’)<ul>
<li>k-means聚类</li>
<li>n_clusters:开始的聚类中心数量</li>
<li>init：初始化方法，默认为‘k-means ++’</li>
<li>labels_:默认标记的类型，可以和真实值比较(不是值比较)</li>
</ul>
</li>
</ul>
<p>聚类做在分类之前.</p>
<p><code>4.聚类评估标准-轮廓系数</code></p>
<script type="math/tex; mode=display">
轮廓系数计算公式：SC_i=\frac{b_i-a_i}{max(b_ia_i)}</script><script type="math/tex; mode=display">
注:对于每个点i为已聚类数据中的样本,b_i为i到其他族群的所有样本的距离最小值，a_i为i到本身簇的距离平均值
\\
最终计算出所有的样本点的轮廓系数平均值</script><p><img src="../images/Python机器学习算法/聚类样本分析.png" alt=""></p>
<p>对于每一个样本都有一个轮廓系数[-1,1]</p>
<p>1.计算蓝1到自身类别的点距离的平均值a_i</p>
<p>2.计算栏1分别到红色类别，绿色类别所有的点的距离，求出平均值b1,b2,取其中最小值当中b_i</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">极端情况：</span><br><span class="line">b_i&gt;&gt;a_i   1  完美</span><br><span class="line">a_i&gt;&gt;b_i   -1 最差</span><br><span class="line">得出轮廓系数的范围:[-1,1]</span><br></pre></td></tr></table></figure>
<p>性能评估指标API:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.silhouette_score</span><br></pre></td></tr></table></figure>
<ul>
<li>sklearn.metrics.silhouette_score(X,labels)<ul>
<li>计算所有样本的平均轮廓系数</li>
<li>X：特征值</li>
<li>labels：被聚类标记的目标值</li>
</ul>
</li>
</ul>
<p><code>5.kmeans特点分析</code></p>
<p>特点分析：采用迭代式算法，直观易懂并且非常实用</p>
<p>缺点：容易收敛到局部最优解(多次聚类)</p>
<p>注意:聚类一般做在分类之前</p>
<h4 id="EM算法："><a href="#EM算法：" class="headerlink" title="EM算法："></a>EM算法：</h4><p>EM（Expectation-Maximization）算法是一种迭代方法，用于在概率模型中有隐藏变量的情况下进行最大似然估计</p>
<h5 id="1-最大似然"><a href="#1-最大似然" class="headerlink" title="1.最大似然"></a>1.最大似然</h5><p>极大似然估计就是用来估计模型参数的统计学方法</p>
<p>在已知(1)样本服从分布的模型，（2)观测到的样本，求解模型的参数</p>
<p>最大似然数学问题：100名学生的身高问题</p>
<ul>
<li>样本集X={x_1,x_2,…,X_N}N=100</li>
<li>概率密度:p(xi|θ)抽到男生i(的身高)的概率</li>
<li>θ是服从分布的参数</li>
<li>独立同分布:同时抽到这100个男生的概率就是他们各自概率的乘积</li>
</ul>
<h5 id="2-EM算法推导"><a href="#2-EM算法推导" class="headerlink" title="2.EM算法推导"></a>2.EM算法推导</h5><h5 id="3-GMM-高斯混合模型"><a href="#3-GMM-高斯混合模型" class="headerlink" title="3.GMM(高斯混合模型)"></a>3.GMM(高斯混合模型)</h5><h4 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h4><h4 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h4><h3 id="day04-课程第四天"><a href="#day04-课程第四天" class="headerlink" title="day04 课程第四天"></a>day04 课程第四天</h3><h4 id="1-深度学习介绍"><a href="#1-深度学习介绍" class="headerlink" title="1.深度学习介绍"></a>1.深度学习介绍</h4><p>深度学习代表性的场景应用:图像理解，语言识别，自然语言处理，机器自主。</p>
<p>深度学习:如深度神经网络，卷积神经网络和递归神经网络已被应用计算机视觉，语音识别，自然语言处理，音频识别与生物信息学等领域并获取了极好的效果。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>机器学习</th>
<th>深度学习</th>
</tr>
</thead>
<tbody>
<tr>
<td>算法</td>
<td>分类:神经网络(简单的)</td>
<td>神经网络(深度),卷积神经网络(图像)，循环神经网络(自然语言处理)</td>
</tr>
<tr>
<td>领域</td>
<td>传统预测问题</td>
<td>图像等领域</td>
</tr>
</tbody>
</table>
</div>
<p>深度学习的框架：<code>TensorFlow</code>,<code>Torch</code></p>
<h4 id="2-认识Tensorflow"><a href="#2-认识Tensorflow" class="headerlink" title="2.认识Tensorflow"></a>2.认识Tensorflow</h4><p>TensorBoard:可视化</p>
<p><code>Tensorflow的特点</code>:</p>
<p>1、<strong>真正的可移植性</strong><br> 引入各种计算设备的支持包括CPU/GPU/TPU，以及能够很好地运行在移动端，如安卓设备、ios、树莓派等等</p>
<p>2、<strong>多语言支持</strong><br> TensorFlow有一个合理的C++使用界面，也有一个易用的Python使用界面来构建和执行你的graphs，你可以直接写Python/C++程序。</p>
<p>3、<strong>高度的灵活性与效率</strong><br> TensorFlow是一个采用数据流图（data flow graphs），用于数值计算的开源软件库，能够灵活进行组装图，执行图。随着开发的进展，TensorFlow的效率不断在提高。</p>
<p>4、<strong>支持</strong><br> TensorFlow由谷歌提供支持，谷歌投入了大量精力开发TensorFlow，它希望TensorFlow成为机器学习研究人员和开发人员的通用语言。</p>
<p>国内使用Tensorflow的公司:小米，京东等</p>
<p><code>Tensorflow的版本</code>：</p>
<p>0.12版本之后支持的可视化，能够可视化的看见程序图的结构。</p>
<p>gpu版本</p>
<p>cpu版本</p>
<h4 id="3-Tensorflow的安装"><a href="#3-Tensorflow的安装" class="headerlink" title="3.Tensorflow的安装"></a>3.Tensorflow的安装</h4><p>当数据量大，特征多或者算法本身设计的比较复杂，运算</p>
<p>cpu:运行操作系统，处理业务，计算能力不突出</p>
<p>gpu:专门为计算设计的，速度会快很多</p>
<p>GPU版本环境搭建</p>
<p>Linux/Ubuntu</p>
<p>用于在不同的操作系统和Python版本下安装TensorFlow 1.0.1版本</p>
<ul>
<li><p>Python 2.7:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.0.1-cp27-none-linux_x86_64.whl</span><br></pre></td></tr></table></figure>
</li>
<li><p>Python 3.5:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.0.1-cp35-cp35m-linux_x86_64.whl</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>macOS</p>
<ul>
<li><p>Python 2.7:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.0.1-py2-none-any.whl</span><br></pre></td></tr></table></figure>
</li>
<li><p>Python 3:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.0.1-py3-none-any.whl</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="4-Tensorflow基础"><a href="#4-Tensorflow基础" class="headerlink" title="4.Tensorflow基础"></a>4.Tensorflow基础</h4><h4 id="5-Tensorflow进阶"><a href="#5-Tensorflow进阶" class="headerlink" title="5.Tensorflow进阶"></a>5.Tensorflow进阶</h4><h4 id="6-案例-实现线性回归"><a href="#6-案例-实现线性回归" class="headerlink" title="6.案例-实现线性回归"></a>6.案例-实现线性回归</h4>
    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/WeChat.png" alt="Amber 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.png" alt="Amber 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Amber
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://readmengk90.github.io/2024/11/25/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/" title="Python机器学习">https://readmengk90.github.io/2024/11/25/Python机器学习算法/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Python/" rel="tag"># Python</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/11/14/Python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" rel="prev" title="Python数据分析">
      <i class="fa fa-chevron-left"></i> Python数据分析
    </a></div>
      <div class="post-nav-item">
    <a href="/2024/12/10/%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95-%E7%A7%91%E6%8A%80%E6%96%87%E7%8C%AE%E6%A3%80%E7%B4%A2%E4%B8%8E%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C/" rel="next" title="科研文献检索">
      科研文献检索 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">机器学习简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#day01-%E6%95%B0%E6%8D%AE%E7%9A%84%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="nav-number">2.</span> <span class="nav-text">day01:数据的特征工程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0"><span class="nav-number">2.1.</span> <span class="nav-text">机器学习概述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%9E%84%E6%88%90"><span class="nav-number">2.2.</span> <span class="nav-text">数据集的构成</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E7%BB%93%E6%9E%84%E7%BB%84%E6%88%90"><span class="nav-number">2.3.</span> <span class="nav-text">数据集的结构组成</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%AF%B9%E7%89%B9%E5%BE%81%E7%9A%84%E5%A4%84%E7%90%86"><span class="nav-number">2.4.</span> <span class="nav-text">数据中对特征的处理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E7%9A%84%E6%84%8F%E4%B9%89"><span class="nav-number">2.5.</span> <span class="nav-text">特征工程的意义:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#scikit-learn%E5%BA%93%E7%9A%84%E4%BB%8B%E7%BB%8D%EF%BC%9A"><span class="nav-number">2.6.</span> <span class="nav-text">scikit-learn库的介绍：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E7%9A%84%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96"><span class="nav-number">2.7.</span> <span class="nav-text">数据的特征抽取:</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%961"><span class="nav-number">2.7.1.</span> <span class="nav-text">文本特征抽取1:</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96%E6%96%B9%E5%BC%8F2"><span class="nav-number">2.7.2.</span> <span class="nav-text">文本特征抽取方式2:</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E7%9A%84%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-number">2.8.</span> <span class="nav-text">数据的特征预处理:</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%BD%92%E4%B8%80%E5%8C%96%EF%BC%9A"><span class="nav-number">2.8.1.</span> <span class="nav-text">归一化：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A0%87%E5%87%86%E5%8C%96%EF%BC%9A"><span class="nav-number">2.8.2.</span> <span class="nav-text">标准化：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95"><span class="nav-number">2.8.3.</span> <span class="nav-text">缺失值处理方法:</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E7%9A%84%E9%99%8D%E7%BB%B4"><span class="nav-number">2.9.</span> <span class="nav-text">数据的降维:</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9"><span class="nav-number">2.9.1.</span> <span class="nav-text">特征选择</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-PCA"><span class="nav-number">2.9.2.</span> <span class="nav-text">主成分分析(PCA)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#day02-%E8%AF%BE%E7%A8%8B%E7%AC%AC%E4%BA%8C%E5%A4%A9"><span class="nav-number">3.</span> <span class="nav-text">day02 课程第二天</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#sklearn%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8E%E4%BC%B0%E8%AE%A1%E5%99%A8"><span class="nav-number">3.1.</span> <span class="nav-text">sklearn数据集与估计器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80"><span class="nav-number">3.2.</span> <span class="nav-text">机器学习基础</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95-k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95-%E5%BD%92%E4%B8%80%E5%8C%96%E5%A4%84%E7%90%86"><span class="nav-number">3.3.</span> <span class="nav-text">分类算法-k近邻算法(归一化处理)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95"><span class="nav-number">3.4.</span> <span class="nav-text">分类算法-朴素贝叶斯算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95%E5%AE%9E%E5%88%97"><span class="nav-number">3.5.</span> <span class="nav-text">朴素贝叶斯算法实列</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%89%E6%8B%A9%E4%B8%8E%E8%B0%83%E4%BC%98"><span class="nav-number">3.6.</span> <span class="nav-text">模型的选择与调优</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#day03-%E8%AF%BE%E7%A8%8B%E7%AC%AC%E4%B8%89%E5%A4%A9"><span class="nav-number">4.</span> <span class="nav-text">day03 课程第三天</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81-cross-validation"><span class="nav-number">4.1.</span> <span class="nav-text">交叉验证(cross validation)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#K%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%EF%BC%88k-fold-cross-validation%EF%BC%89"><span class="nav-number">4.2.</span> <span class="nav-text">K折交叉验证（k-fold cross validation）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2-Grid-Search-%EF%BC%9A"><span class="nav-number">4.3.</span> <span class="nav-text">网格搜索(Grid Search)：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95-%E5%86%B3%E7%AD%96%E6%A0%91"><span class="nav-number">4.4.</span> <span class="nav-text">分类算法-决策树</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%EF%BC%88%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%EF%BC%89"><span class="nav-number">4.5.</span> <span class="nav-text">分类算法-随机森林（集成学习方法）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90"><span class="nav-number">4.6.</span> <span class="nav-text">回归算法-线性回归分析</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%AE%9E%E4%BE%8B-%E9%9C%80%E8%A6%81%E5%81%9A%E6%A0%87%E5%87%86%E5%8C%96%E5%A4%84%E7%90%86%E3%80%90K%E8%BF%91%E9%82%BB-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E3%80%91"><span class="nav-number">4.7.</span> <span class="nav-text">线性回归实例(需要做标准化处理【K近邻+线性回归】)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%9E%E9%A1%BE%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0"><span class="nav-number">4.8.</span> <span class="nav-text">回顾性能评估</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="nav-number">4.9.</span> <span class="nav-text">分类算法-逻辑回归</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95-kmeans%E5%8E%9F%E7%90%86"><span class="nav-number">4.10.</span> <span class="nav-text">聚类算法-kmeans原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#EM%E7%AE%97%E6%B3%95%EF%BC%9A"><span class="nav-number">4.11.</span> <span class="nav-text">EM算法：</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6"><span class="nav-number">4.11.1.</span> <span class="nav-text">1.最大似然</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-EM%E7%AE%97%E6%B3%95%E6%8E%A8%E5%AF%BC"><span class="nav-number">4.11.2.</span> <span class="nav-text">2.EM算法推导</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-GMM-%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B"><span class="nav-number">4.11.3.</span> <span class="nav-text">3.GMM(高斯混合模型)</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="nav-number">4.12.</span> <span class="nav-text">支持向量机</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">4.13.</span> <span class="nav-text">神经网络</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#day04-%E8%AF%BE%E7%A8%8B%E7%AC%AC%E5%9B%9B%E5%A4%A9"><span class="nav-number">5.</span> <span class="nav-text">day04 课程第四天</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%8B%E7%BB%8D"><span class="nav-number">5.1.</span> <span class="nav-text">1.深度学习介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E8%AE%A4%E8%AF%86Tensorflow"><span class="nav-number">5.2.</span> <span class="nav-text">2.认识Tensorflow</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-Tensorflow%E7%9A%84%E5%AE%89%E8%A3%85"><span class="nav-number">5.3.</span> <span class="nav-text">3.Tensorflow的安装</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-Tensorflow%E5%9F%BA%E7%A1%80"><span class="nav-number">5.4.</span> <span class="nav-text">4.Tensorflow基础</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-Tensorflow%E8%BF%9B%E9%98%B6"><span class="nav-number">5.5.</span> <span class="nav-text">5.Tensorflow进阶</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-%E6%A1%88%E4%BE%8B-%E5%AE%9E%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">5.6.</span> <span class="nav-text">6.案例-实现线性回归</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Amber"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Amber</p>
  <div class="site-description" itemprop="description">programming study</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">75</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="mailto:2770576166@qq.com" title="E-Mail → mailto:2770576166@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.google.com.hk/" title="Google → https:&#x2F;&#x2F;www.google.com.hk&#x2F;" rel="noopener" target="_blank"><i class="fab fa-google fa-fw"></i>Google</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://github.com/readMengK90/readMengK90.github.io" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;readMengK90&#x2F;readMengK90.github.io" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Amber</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">170k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">5:09</span>
</div>
  <div class="powered-by">
    
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
